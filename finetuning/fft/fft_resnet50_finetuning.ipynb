{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfjvgnO1hAYo",
        "outputId": "1beea4db-aea2-4a75-d53c-36ae3195b1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "===== START =====\n",
            "DEVICE: cuda\n",
            "Real: 34681, Fake: 33854\n",
            "\n",
            "[샘플링] 최대 10000개 중 10000개 사용\n",
            "→ 샘플링 완료: 10000개\n",
            "\n",
            "Train 7000  Val 2000  Test 1000\n",
            "\n",
            "=== Loading resnet50 (pretrained, mode=full, use_fft=True) ===\n",
            "→ 전체 파라미터 Fine-Tuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 1/30: 100%|██████████| 110/110 [01:53<00:00,  1.03s/it]\n",
            "Val Epoch 1/30: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Train Loss 0.5685 Acc 0.6933 | Val Loss 0.5059 Acc 0.7460\n",
            "→ Best model 갱신\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 2/30: 100%|██████████| 110/110 [01:51<00:00,  1.01s/it]\n",
            "Val Epoch 2/30: 100%|██████████| 32/32 [00:28<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2] Train Loss 0.4417 Acc 0.7833 | Val Loss 0.4885 Acc 0.7505\n",
            "→ Best model 갱신\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 3/30: 100%|██████████| 110/110 [01:23<00:00,  1.31it/s]\n",
            "Val Epoch 3/30: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3] Train Loss 0.3475 Acc 0.8394 | Val Loss 0.5227 Acc 0.7550\n",
            "→ 개선 없음 (1/3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 4/30: 100%|██████████| 110/110 [01:11<00:00,  1.54it/s]\n",
            "Val Epoch 4/30: 100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4] Train Loss 0.2689 Acc 0.8870 | Val Loss 0.5447 Acc 0.7525\n",
            "→ 개선 없음 (2/3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 5/30: 100%|██████████| 110/110 [01:13<00:00,  1.50it/s]\n",
            "Val Epoch 5/30: 100%|██████████| 32/32 [00:16<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] Train Loss 0.1940 Acc 0.9186 | Val Loss 0.6614 Acc 0.7545\n",
            "→ 개선 없음 (3/3)\n",
            "EARLY STOPPING!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST: 100%|██████████| 16/16 [00:07<00:00,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss: 0.4829\n",
            "Test Accuracy: 75.40%\n",
            "===== DONE =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 0. 기본 설정 & 라이브러리\n",
        "# ==============================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "from torchvision.models import (\n",
        "    googlenet, GoogLeNet_Weights,\n",
        "    resnet50, ResNet50_Weights,\n",
        "    vgg16, VGG16_Weights,\n",
        "    vit_b_16, ViT_B_16_Weights\n",
        ")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ==============================\n",
        "# 1. 설정값 & 경로\n",
        "# ==============================\n",
        "BASE_DIR = \"/content/drive/MyDrive/기학기\"\n",
        "REAL_PATH = BASE_DIR + \"/face_real\"\n",
        "FAKE_PATH = BASE_DIR + \"/face_fake\"\n",
        "MODEL_SAVE_PATH = \"/content/best_googlenet_fft.pth\"\n",
        "\n",
        "IMG_SIZE = 224\n",
        "EPOCHS = 30          # 필요한 만큼 조절 가능\n",
        "BATCH_SIZE = 64\n",
        "NUM_SAMPLES = 10000  # 전체에서 샘플링할 최대 개수\n",
        "LEARNING_RATE = 1e-4\n",
        "PATIENCE = 3         # early stopping 기준\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 2. ResizeWithPad\n",
        "# ==============================\n",
        "class ResizeWithPad:\n",
        "    \"\"\"긴 변 기준으로 리사이즈 후, 짧은 변은 패딩해서 정사각형으로 맞추는 Transform (PIL -> PIL)\"\"\"\n",
        "    def __init__(self, target_size):\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        scale = self.target_size / max(w, h)\n",
        "\n",
        "        new_w = int(w * scale)\n",
        "        new_h = int(h * scale)\n",
        "\n",
        "        resized_img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "        canvas = Image.new(\"RGB\", (self.target_size, self.target_size), (0, 0, 0))\n",
        "\n",
        "        pad_x = (self.target_size - new_w) // 2\n",
        "        pad_y = (self.target_size - new_h) // 2\n",
        "        canvas.paste(resized_img, (pad_x, pad_y))\n",
        "\n",
        "        return canvas\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 3. FFT Magnitude Transform\n",
        "# ==============================\n",
        "class FFTMag:\n",
        "    \"\"\"\n",
        "    Tensor(C,H,W)를 받아 채널별로 2D FFT -> 중심 이동(fftshift) -> magnitude -> log1p\n",
        "    그 다음 전체를 평균 0, 표준편차 1로 정규화해서 반환\n",
        "    (출력 shape는 입력과 동일: [C, H, W])\n",
        "    \"\"\"\n",
        "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: [C, H, W], float32\n",
        "        # 2D FFT (채널별)\n",
        "        x_fft = torch.fft.fft2(x)               # complex tensor\n",
        "        x_fft_shift = torch.fft.fftshift(x_fft) # 저주파를 중앙으로 이동\n",
        "        mag = torch.abs(x_fft_shift)            # magnitude\n",
        "        mag = torch.log1p(mag)                  # log(1 + |F|)\n",
        "\n",
        "        # 채널 전체 기준으로 표준화\n",
        "        mean = mag.mean()\n",
        "        std = mag.std()\n",
        "        mag = (mag - mean) / (std + 1e-8)\n",
        "\n",
        "        return mag\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 4. Dataset\n",
        "# ==============================\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.paths[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)  # Tensor(C,H,W), 이미 FFT까지 처리된 상태\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return img, label.unsqueeze(0)  # (1,) 형태로 맞춰줌\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 5. Fine-Tuning 모델\n",
        "# ==============================\n",
        "def get_model_finetune(name, device, mode=\"full\"):\n",
        "    \"\"\"\n",
        "    name: 'googlenet', 'resnet50', 'vgg16', 'vit' 중 하나\n",
        "    mode: 'head' -> classifier만 학습, 'full' -> 전체 파라미터 학습\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Loading {name} (pretrained, mode={mode}, use_fft=True) ===\")\n",
        "\n",
        "    if name == \"googlenet\":\n",
        "        weights = GoogLeNet_Weights.DEFAULT\n",
        "        # aux_logits=True가 기본이므로 굳이 인자 안 넘김 (ValueError 피하기 위해)\n",
        "        model = googlenet(weights=weights)\n",
        "        in_f = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_f, 1)\n",
        "        head_params = model.fc.parameters()\n",
        "\n",
        "    elif name == \"resnet50\":\n",
        "        weights = ResNet50_Weights.DEFAULT\n",
        "        model = resnet50(weights=weights)\n",
        "        in_f = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_f, 1)\n",
        "        head_params = model.fc.parameters()\n",
        "\n",
        "    elif name == \"vgg16\":\n",
        "        weights = VGG16_Weights.DEFAULT\n",
        "        model = vgg16(weights=weights)\n",
        "        in_f = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Linear(in_f, 1)\n",
        "        head_params = model.classifier[6].parameters()\n",
        "\n",
        "    elif name == \"vit\":\n",
        "        weights = ViT_B_16_Weights.DEFAULT\n",
        "        model = vit_b_16(weights=weights)\n",
        "        in_f = model.heads.head.in_features\n",
        "        model.heads.head = nn.Linear(in_f, 1)\n",
        "        head_params = model.heads.head.parameters()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"지원하지 않는 모델 이름입니다.\")\n",
        "\n",
        "    # Freeze 설정\n",
        "    if mode == \"head\":\n",
        "        print(\"→ Classifier만 학습 (Feature extractor는 Freeze)\")\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = False\n",
        "        for p in head_params:\n",
        "            p.requires_grad = True\n",
        "    else:\n",
        "        print(\"→ 전체 파라미터 Fine-Tuning\")\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "    return model.to(device)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 6. Train\n",
        "# ==============================\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, patience):\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_model = None\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total, correct = 0, 0\n",
        "        running_loss = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}/{epochs}\")\n",
        "        for X, y in pbar:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X)\n",
        "\n",
        "            # GoogLeNet의 경우 출력이 GoogLeNetOutputs(logits, aux_logits) 형태일 수 있음\n",
        "            if hasattr(out, \"logits\"):\n",
        "                out = out.logits\n",
        "            elif isinstance(out, (tuple, list)):\n",
        "                out = out[0]\n",
        "\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * X.size(0)\n",
        "            pred = (torch.sigmoid(out) > 0.5).float()\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # ---------------------- Validation --------------------------\n",
        "        model.eval()\n",
        "        total, correct = 0, 0\n",
        "        running_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y in tqdm(val_loader, desc=f\"Val Epoch {epoch+1}/{epochs}\"):\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                out = model(X)\n",
        "\n",
        "                if hasattr(out, \"logits\"):\n",
        "                    out = out.logits\n",
        "                elif isinstance(out, (tuple, list)):\n",
        "                    out = out[0]\n",
        "\n",
        "                loss = criterion(out, y)\n",
        "\n",
        "                running_val += loss.item() * X.size(0)\n",
        "                pred = (torch.sigmoid(out) > 0.5).float()\n",
        "                correct += (pred == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "        val_loss = running_val / len(val_loader.dataset)\n",
        "        val_acc = correct / total\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}] Train Loss {train_loss:.4f} Acc {train_acc:.4f} | \"\n",
        "              f\"Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            no_improve = 0\n",
        "            print(\"→ Best model 갱신\")\n",
        "            torch.save(best_model, MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            print(f\"→ 개선 없음 ({no_improve}/{patience})\")\n",
        "            if no_improve >= patience:\n",
        "                print(\"EARLY STOPPING!\")\n",
        "                break\n",
        "\n",
        "    if best_model is not None:\n",
        "        model.load_state_dict(best_model)\n",
        "    return model\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 7. Evaluate\n",
        "# ==============================\n",
        "def evaluate_model(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    running_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(loader, desc=\"TEST\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            out = model(X)\n",
        "\n",
        "            if hasattr(out, \"logits\"):\n",
        "                out = out.logits\n",
        "            elif isinstance(out, (tuple, list)):\n",
        "                out = out[0]\n",
        "\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            running_loss += loss.item() * X.size(0)\n",
        "            pred = (torch.sigmoid(out) > 0.5).float()\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    print(f\"\\nTest Loss: {running_loss/len(loader.dataset):.4f}\")\n",
        "    print(f\"Test Accuracy: {correct/total*100:.2f}%\")\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 8. MAIN\n",
        "# ==============================\n",
        "def main():\n",
        "    print(\"===== START =====\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"DEVICE:\", device)\n",
        "\n",
        "    # --- 경로에서 이미지 읽기 ---\n",
        "    real_paths = glob.glob(os.path.join(REAL_PATH, \"*\"))\n",
        "    fake_paths = glob.glob(os.path.join(FAKE_PATH, \"*\"))\n",
        "\n",
        "    print(f\"Real: {len(real_paths)}, Fake: {len(fake_paths)}\")\n",
        "\n",
        "    if len(real_paths) == 0 or len(fake_paths) == 0:\n",
        "        print(\"❌ Real 또는 Fake 폴더에 이미지가 없습니다. 경로 다시 확인하세요.\")\n",
        "        return\n",
        "\n",
        "    all_paths = real_paths + fake_paths\n",
        "    all_labels = [0]*len(real_paths) + [1]*len(fake_paths)\n",
        "\n",
        "    # --- NUM_SAMPLES 만큼 stratified 샘플링 (train_size 사용) ---\n",
        "    use_num = min(NUM_SAMPLES, len(all_paths))\n",
        "    print(f\"\\n[샘플링] 최대 {NUM_SAMPLES}개 중 {use_num}개 사용\")\n",
        "\n",
        "    if use_num == len(all_paths):\n",
        "        sample_paths = all_paths\n",
        "        sample_labels = all_labels\n",
        "        print(\"→ 전체 데이터 사용\")\n",
        "    else:\n",
        "        sample_paths, _, sample_labels, _ = train_test_split(\n",
        "            all_paths, all_labels,\n",
        "            train_size=use_num,\n",
        "            stratify=all_labels,\n",
        "            random_state=42\n",
        "        )\n",
        "        print(f\"→ 샘플링 완료: {len(sample_paths)}개\")\n",
        "\n",
        "    # --- Train / Val / Test 분할 ---\n",
        "    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "        sample_paths, sample_labels, test_size=0.3, stratify=sample_labels, random_state=42\n",
        "    )\n",
        "    val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "        temp_paths, temp_labels, test_size=1/3, stratify=temp_labels, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTrain {len(train_paths)}  Val {len(val_paths)}  Test {len(test_paths)}\")\n",
        "\n",
        "    # --- Transform 정의 (FFT 포함) ---\n",
        "    train_tf = transforms.Compose([\n",
        "        ResizeWithPad(IMG_SIZE),     # PIL -> PIL\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),       # PIL -> Tensor\n",
        "        FFTMag()                     # Tensor -> FFT Magnitude Tensor\n",
        "    ])\n",
        "\n",
        "    test_tf = transforms.Compose([\n",
        "        ResizeWithPad(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        FFTMag()\n",
        "    ])\n",
        "\n",
        "    # --- DataLoader (디스크에서 바로 읽기) ---\n",
        "    train_loader = DataLoader(\n",
        "        DeepfakeDataset(train_paths, train_labels, train_tf),\n",
        "        batch_size=BATCH_SIZE, shuffle=True,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        DeepfakeDataset(val_paths, val_labels, test_tf),\n",
        "        batch_size=BATCH_SIZE, shuffle=False,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        DeepfakeDataset(test_paths, test_labels, test_tf),\n",
        "        batch_size=BATCH_SIZE, shuffle=False,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "\n",
        "    # --- 모델/옵티마 정의 ---\n",
        "    model = get_model_finetune(\"resnet50\", device, mode=\"full\")\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # --- 학습 ---\n",
        "    model = train_model(model, train_loader, val_loader, criterion, optimizer, device, EPOCHS, PATIENCE)\n",
        "\n",
        "    # --- 평가 ---\n",
        "    evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "    print(\"===== DONE =====\")\n",
        "\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}