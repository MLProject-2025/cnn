{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDQ4Bfs6dACA"
      },
      "source": [
        "local에서 실험 할 CNN 목록\n",
        "\n",
        "Gemini 사용하여 pytorch로 구현\n",
        "\n",
        "Alexnet, Vgg16, googlenet, resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZI6JTtldACE",
        "outputId": "1b9878ec-cfc6-45c6-e64e-e3681d7632d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oK15SvEFdACG"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_file_name = '/content/drive/MyDrive/기학기/real_fake_dataset.zip'\n",
        "extraction_dir = '/content/dataset'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EJWtewChprMW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import time\n",
        "import copy\n",
        "\n",
        "\n",
        "# import h5py\n",
        "# import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2sLf4UV1dACK"
      },
      "outputs": [],
      "source": [
        "# 설정값\n",
        "\n",
        "IMG_SIZE = 224\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "NUM_SAMPLES = 10000\n",
        "LEARNING_RATE = 1e-4\n",
        "PATIENCE = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TRjdsrnidACL"
      },
      "outputs": [],
      "source": [
        "# 이미지 전처리 클래스\n",
        "# 비율 유지하며 resize 후 패딩 추가(0으로)\n",
        "class ResizeWithPad:\n",
        "    def __init__(self, target_size):\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "\n",
        "        scale = self.target_size / max(w, h)\n",
        "\n",
        "        new_w = int(w * scale)\n",
        "        new_h = int(h * scale)\n",
        "\n",
        "        # 비율 유지하며 리사이즈\n",
        "        resized_img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "        # 검은색 캔버스 생성\n",
        "        canvas = Image.new(\"RGB\", (self.target_size, self.target_size), (0, 0, 0))\n",
        "\n",
        "        # 캔버스 중앙에 리사이즈된 이미지 배치\n",
        "        pad_x = (self.target_size - new_w) // 2\n",
        "        pad_y = (self.target_size - new_h) // 2\n",
        "\n",
        "        canvas.paste(resized_img, (pad_x, pad_y))\n",
        "\n",
        "        return canvas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PpzKAxb3-neB"
      },
      "outputs": [],
      "source": [
        "# 데이터셋\n",
        "# 디스크의 이미지 경로 리스트를 받아,\n",
        "# 배치 생성 시점에만 이미지를 읽어옴\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 디스크에서 이미지 경로로 이미지 로드 (PIL)\n",
        "        img_path = self.paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # 전처리 적용\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # 라벨을 float 텐서로 변환 (BCEWithLogitsLoss용)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        return image, label.unsqueeze(0) # (1,) 형태로 반환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LtDP02qNtpRB"
      },
      "outputs": [],
      "source": [
        "class AlexNetLike(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(AlexNetLike, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv 1\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), # 224 -> 55\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 55 -> 27\n",
        "\n",
        "            # Conv 2\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2), # 27 -> 27\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 27 -> 13\n",
        "\n",
        "            # Conv 3\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 4\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 5\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 13 -> 6\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num_classes) # num_classes=1\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x); x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1); x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q1q1ozwadACP"
      },
      "outputs": [],
      "source": [
        "def get_model(model_name, device):\n",
        "\n",
        "    model = None\n",
        "    num_classes = 1 # 이진 분류 (Real/Fake)\n",
        "\n",
        "    print(f\"Loading {model_name} architecture (FROM SCRATCH)...\")\n",
        "\n",
        "    if model_name.lower() == 'alexnet':\n",
        "        # 직접 짠 AlexNet (Conv 5, FC 3)\n",
        "        model = AlexNetLike(num_classes=num_classes)\n",
        "\n",
        "    elif model_name.lower() == 'vgg16':\n",
        "        # VGG16\n",
        "        model = models.vgg16(weights=None, num_classes=num_classes)\n",
        "\n",
        "    elif model_name.lower() == 'googlenet':\n",
        "        # GoogLeNet\n",
        "        model = models.googlenet(weights=None, num_classes=num_classes, aux_logits=False)\n",
        "\n",
        "    elif model_name.lower() == 'resnet50':\n",
        "        # ResNet50\n",
        "        model = models.resnet50(weights=None, num_classes=num_classes)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}. Choose from 'alexnet, 'vgg16', 'googlenet', 'resnet50'\")\n",
        "\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H56_ULwNi61i"
      },
      "outputs": [],
      "source": [
        "# 학습\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, patience):\n",
        "    print(\"=== 학습 시작 ===\")\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_weights = None\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # --- 훈련 ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # tqdm으로 진행 상황 표시\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
        "\n",
        "        for images, labels in train_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # 순전파\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 역전파 및 최적화\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # 정확도 계산\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "            train_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = correct_train / total_train\n",
        "\n",
        "        # --- 검증 ---\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
        "            for images, labels in val_pbar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item() * images.size(0)\n",
        "\n",
        "                preds = torch.sigmoid(outputs) > 0.5\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = correct_val / total_val\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - {elapsed_time:.0f}s - \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} - \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "        # --- Early Stopping 및 Best Model 저장 ---\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            print(f\"  Validation loss decreased ({best_val_loss:.4f} --> {epoch_val_loss:.4f}). Saving model...\")\n",
        "            best_val_loss = epoch_val_loss\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_weights, MODEL_SAVE_PATH)\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"  Validation loss did not improve. Patience: {epochs_no_improve}/{patience}\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "\n",
        "    print(\"=== 학습 완료 ===\")\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-Z-EU4NZdACR"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    print(\"\\n=== 테스트셋 평가 시작 ===\")\n",
        "    with torch.no_grad():\n",
        "        test_pbar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n",
        "        for images, labels in test_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_test_loss += loss.item() * images.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (preds == labels).sum().item()\n",
        "\n",
        "    test_loss = running_test_loss / len(test_loader.dataset)\n",
        "    test_acc = correct_test / total_test\n",
        "\n",
        "    print(f\"===== 최종 테스트 결과 =====\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvBqcRQAdACS",
        "outputId": "c6282627-b9cf-4dc0-cc74-9470fce62192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "이미지 경로 수집 중...\n",
            "총 68479개 이미지 경로 발견.\n",
            "10000개 샘플을 샘플링...\n",
            "샘플링 완료: 10000개 이미지 선택.\n"
          ]
        }
      ],
      "source": [
        "# 메인 실행\n",
        "start_time = time.time()\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# === 데이터 경로 수정 ===\n",
        "base_dir = \"/content/dataset/real_fake_dataset\"\n",
        "face_real_dir = os.path.join(base_dir, \"face_real\")\n",
        "face_fake_dir = os.path.join(base_dir, \"face_fake\")\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/deepfake_baseline_model.pth\"\n",
        "\n",
        "print(\"이미지 경로 수집 중...\")\n",
        "real_paths = glob.glob(os.path.join(face_real_dir, \"*\"))\n",
        "fake_paths = glob.glob(os.path.join(face_fake_dir, \"*\"))\n",
        "\n",
        "all_paths = real_paths + fake_paths\n",
        "all_labels = [0] * len(real_paths) + [1] * len(fake_paths)\n",
        "\n",
        "print(f\"총 {len(all_labels)}개 이미지 경로 발견.\")\n",
        "\n",
        "# 샘플 개수 제한\n",
        "NUM_SAMPLES = min(NUM_SAMPLES, len(all_paths))\n",
        "\n",
        "print(f\"{NUM_SAMPLES}개 샘플을 샘플링...\")\n",
        "_, target_paths, _, target_labels = train_test_split(\n",
        "    all_paths, all_labels,\n",
        "    test_size=NUM_SAMPLES,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "\n",
        "print(f\"샘플링 완료: {len(target_labels)}개 이미지 선택.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGkivn9tdACU",
        "outputId": "28a55af6-2392-4776-a168-3b30c64fabff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터를 7:2:1 비율로 분할합니다...\n",
            "분할 완료: Train 7000개, Validation 2000개, Test 1000개\n",
            "데이터 로더 생성 완료.\n"
          ]
        }
      ],
      "source": [
        "# 7:2:1 분할 (Keras와 동일)\n",
        "print(\"데이터를 7:2:1 비율로 분할합니다...\")\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    target_paths, target_labels, test_size=0.3, random_state=42, stratify=target_labels\n",
        ")\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths, temp_labels, test_size=(1/3), random_state=42, stratify=temp_labels\n",
        ")\n",
        "print(f\"분할 완료: Train {len(train_paths)}개, Validation {len(val_paths)}개, Test {len(test_paths)}개\")\n",
        "\n",
        "# 전처리 및 데이터 로더 정의\n",
        "train_transform = transforms.Compose([\n",
        "    ResizeWithPad(IMG_SIZE),\n",
        "    # transforms.RandomHorizontalFlip(), # 데이터 증강\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # 좌우 반전\n",
        "    transforms.RandomRotation(10),    #+- 10도 회전\n",
        "    transforms.ColorJitter(\n",
        "        brightness=0.2,\n",
        "        contrast=0.2,\n",
        "        saturation=0.2,\n",
        "        hue=0.02\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # -1 ~ 1 정규화\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    ResizeWithPad(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_dataset = DeepfakeDataset(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(val_paths, val_labels, transform=val_test_transform)\n",
        "test_dataset = DeepfakeDataset(test_paths, test_labels, transform=val_test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "\n",
        "print(\"데이터 로더 생성 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cADFHbVMdACU",
        "outputId": "84f03a2d-797c-4a29-e353-3b8f31278727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 전처리를 시작합니다 (모든 데이터를 RAM에 로드)...\n",
            "데이터 로더 생성 완료.\n",
            "Loading googlenet architecture (FROM SCRATCH)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 학습 시작 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - 58s - Train Loss: 0.6849, Train Acc: 0.5611 - Val Loss: 0.6858, Val Acc: 0.5595\n",
            "  Validation loss decreased (inf --> 0.6858). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - 56s - Train Loss: 0.6631, Train Acc: 0.6030 - Val Loss: 0.7001, Val Acc: 0.5560\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - 60s - Train Loss: 0.6506, Train Acc: 0.6161 - Val Loss: 0.7716, Val Acc: 0.5585\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - 56s - Train Loss: 0.6323, Train Acc: 0.6371 - Val Loss: 0.6435, Val Acc: 0.6035\n",
            "  Validation loss decreased (0.6858 --> 0.6435). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - 56s - Train Loss: 0.6128, Train Acc: 0.6561 - Val Loss: 0.6361, Val Acc: 0.6340\n",
            "  Validation loss decreased (0.6435 --> 0.6361). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - 58s - Train Loss: 0.5841, Train Acc: 0.6811 - Val Loss: 0.7810, Val Acc: 0.5760\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - 56s - Train Loss: 0.5633, Train Acc: 0.6946 - Val Loss: 0.5301, Val Acc: 0.7020\n",
            "  Validation loss decreased (0.6361 --> 0.5301). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - 55s - Train Loss: 0.5485, Train Acc: 0.7096 - Val Loss: 0.6251, Val Acc: 0.6615\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - 56s - Train Loss: 0.5337, Train Acc: 0.7190 - Val Loss: 0.5164, Val Acc: 0.7160\n",
            "  Validation loss decreased (0.5301 --> 0.5164). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - 56s - Train Loss: 0.5145, Train Acc: 0.7281 - Val Loss: 1.0521, Val Acc: 0.5655\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - 55s - Train Loss: 0.4941, Train Acc: 0.7429 - Val Loss: 0.4978, Val Acc: 0.7365\n",
            "  Validation loss decreased (0.5164 --> 0.4978). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - 57s - Train Loss: 0.4819, Train Acc: 0.7510 - Val Loss: 1.4927, Val Acc: 0.5185\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - 57s - Train Loss: 0.4707, Train Acc: 0.7589 - Val Loss: 0.8584, Val Acc: 0.6105\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - 57s - Train Loss: 0.4540, Train Acc: 0.7689 - Val Loss: 0.4772, Val Acc: 0.7620\n",
            "  Validation loss decreased (0.4978 --> 0.4772). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - 56s - Train Loss: 0.4423, Train Acc: 0.7774 - Val Loss: 0.5194, Val Acc: 0.7315\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - 56s - Train Loss: 0.4339, Train Acc: 0.7844 - Val Loss: 0.4900, Val Acc: 0.7410\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - 56s - Train Loss: 0.4202, Train Acc: 0.7904 - Val Loss: 0.5105, Val Acc: 0.7255\n",
            "  Validation loss did not improve. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - 55s - Train Loss: 0.4043, Train Acc: 0.8049 - Val Loss: 0.4629, Val Acc: 0.7530\n",
            "  Validation loss decreased (0.4772 --> 0.4629). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - 57s - Train Loss: 0.4007, Train Acc: 0.8039 - Val Loss: 0.5115, Val Acc: 0.7340\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - 56s - Train Loss: 0.3879, Train Acc: 0.8087 - Val Loss: 0.4865, Val Acc: 0.7495\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - 57s - Train Loss: 0.3667, Train Acc: 0.8237 - Val Loss: 0.4528, Val Acc: 0.7740\n",
            "  Validation loss decreased (0.4629 --> 0.4528). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - 57s - Train Loss: 0.3647, Train Acc: 0.8279 - Val Loss: 0.4623, Val Acc: 0.7780\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - 55s - Train Loss: 0.3543, Train Acc: 0.8300 - Val Loss: 0.4650, Val Acc: 0.7840\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - 56s - Train Loss: 0.3446, Train Acc: 0.8399 - Val Loss: 0.5342, Val Acc: 0.7345\n",
            "  Validation loss did not improve. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - 56s - Train Loss: 0.3421, Train Acc: 0.8363 - Val Loss: 0.5127, Val Acc: 0.7580\n",
            "  Validation loss did not improve. Patience: 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - 55s - Train Loss: 0.3363, Train Acc: 0.8387 - Val Loss: 0.4917, Val Acc: 0.7675\n",
            "  Validation loss did not improve. Patience: 5/5\n",
            "Early stopping triggered after 26 epochs.\n",
            "=== 학습 완료 ===\n",
            "\n",
            "=== 테스트셋 평가 시작 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 최종 테스트 결과 =====\n",
            "  Test Loss: 0.4485\n",
            "  Test Accuracy: 79.30%\n",
            "총 실행 시간: 24.56 분\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# 데이터 전처리 및 RAM에 로드\n",
        "print(\"데이터 전처리를 시작합니다 (모든 데이터를 RAM에 로드)...\")\n",
        "start_time = time.time()\n",
        "def load_images_to_ram(paths, transform):\n",
        "    tensor_list = []\n",
        "    for path in tqdm(paths, desc=\"Loading images to RAM\"):\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        tensor_list.append(transform(img))\n",
        "    return torch.stack(tensor_list)\n",
        "\n",
        "# 이미지 필요할 때만 읽어서 GPU에 올림\n",
        "train_dataset = DeepfakeDataset(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(val_paths, val_labels, transform=val_test_transform)\n",
        "test_dataset = DeepfakeDataset(test_paths, test_labels, transform=val_test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "print(\"데이터 로더 생성 완료.\")\n",
        "\n",
        "# 8. 모델, 손실함수, 옵티마이저 정의\n",
        "model = get_model('googlenet', device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 9. 학습 및 평가\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, device, EPOCHS, PATIENCE)\n",
        "evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"총 실행 시간: {(time.time() - start_time) / 60:.2f} 분\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}