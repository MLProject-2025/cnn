{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/sazaqa0901/ML_test/blob/main/deepfake_resnet_s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KuQ-92WQx0En","outputId":"34403572-201c-4383-8907-45d632d8ef49","executionInfo":{"status":"ok","timestamp":1763910312023,"user_tz":-540,"elapsed":46772,"user":{"displayName":"김윤숙","userId":"06661495915909363949"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","zip_file_name = '/content/drive/MyDrive/Dataset.zip'\n","extraction_dir = '/content/dataset'\n","with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n","  zip_ref.extractall(extraction_dir)"],"metadata":{"id":"frg-vDR7x1IN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJWtewChprMW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from PIL import Image\n","\n","import os\n","import glob\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import zipfile\n","import time\n","import copy\n","\n","\n","# import h5py\n","# import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WfsznOINwjeX"},"outputs":[],"source":["# 설정값\n","IMG_SIZE = 224\n","EPOCHS = 30\n","BATCH_SIZE = 64\n","NUM_SAMPLES = 20000\n","LEARNING_RATE = 1e-4\n","PATIENCE = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ak9tUFkiwjeY"},"outputs":[],"source":["# 이미지 전처리 클래스\n","# 비율 유지하며 resize 후 패딩 추가(0으로)\n","class ResizeWithPad:\n","    def __init__(self, target_size):\n","        self.target_size = target_size\n","\n","    def __call__(self, img):\n","        w, h = img.size\n","\n","        scale = self.target_size / max(w, h)\n","\n","        new_w = int(w * scale)\n","        new_h = int(h * scale)\n","\n","        # 비율 유지하며 리사이즈\n","        resized_img = img.resize((new_w, new_h), Image.LANCZOS)\n","\n","        # 검은색 캔버스 생성\n","        canvas = Image.new(\"RGB\", (self.target_size, self.target_size), (0, 0, 0))\n","\n","        # 캔버스 중앙에 리사이즈된 이미지 배치\n","        pad_x = (self.target_size - new_w) // 2\n","        pad_y = (self.target_size - new_h) // 2\n","\n","        canvas.paste(resized_img, (pad_x, pad_y))\n","\n","        return canvas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpzKAxb3-neB"},"outputs":[],"source":["# 데이터셋\n","# 디스크의 이미지 경로 리스트를 받아,\n","# 배치 생성 시점에만 이미지를 읽어옴\n","class DeepfakeDataset(Dataset):\n","    def __init__(self, paths, labels, transform=None):\n","        self.paths = paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        # 디스크에서 이미지 경로로 이미지 로드 (PIL)\n","        img_path = self.paths[idx]\n","        image = Image.open(img_path).convert('RGB')\n","\n","        # 전처리 적용\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # 라벨을 float 텐서로 변환 (BCEWithLogitsLoss용)\n","        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n","\n","        return image, label.unsqueeze(0) # (1,) 형태로 반환\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtDP02qNtpRB"},"outputs":[],"source":["class AlexNetLike(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(AlexNetLike, self).__init__()\n","        self.features = nn.Sequential(\n","            # Conv 1\n","            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), # 224 -> 55\n","            nn.BatchNorm2d(96),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2), # 55 -> 27\n","\n","            # Conv 2\n","            nn.Conv2d(96, 256, kernel_size=5, padding=2), # 27 -> 27\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2), # 27 -> 13\n","\n","            # Conv 3\n","            nn.Conv2d(256, 384, kernel_size=3, padding=1), # 13 -> 13\n","            nn.BatchNorm2d(384),\n","            nn.ReLU(inplace=True),\n","\n","            # Conv 4\n","            nn.Conv2d(384, 384, kernel_size=3, padding=1), # 13 -> 13\n","            nn.BatchNorm2d(384),\n","            nn.ReLU(inplace=True),\n","\n","            # Conv 5\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1), # 13 -> 13\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2), # 13 -> 6\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(256 * 6 * 6, 1024),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, 1024),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(1024, num_classes) # num_classes=1\n","        )\n","    def forward(self, x):\n","        x = self.features(x); x = self.avgpool(x)\n","        x = torch.flatten(x, 1); x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqWWMXSPwjea"},"outputs":[],"source":["from torchvision import models\n","from torchvision.models import GoogLeNet_Weights\n","import torch.nn as nn\n","\n","def get_model(model_name, device, use_pretrained=True):\n","\n","    model = None\n","    num_classes = 1 #이진 분류 (Real/Fake)\n","\n","    weights = models.GoogLeNet_Weights.IMAGENET1K_V1 if use_pretrained else None\n","\n","    print(f\"Loading {model_name} architecture...\")\n","    if use_pretrained:\n","        print(\"  Using ImageNet Pre-trained Weights.\")\n","    else:\n","        print(\"  Training FROM SCRATCH (No Pre-trained Weights).\")\n","\n","    if model_name.lower() == 'alexnet':\n","        # 직접(동욱) 짠 AlexNet\n","        model = AlexNetLike(num_classes=num_classes)\n","        print(\"  Note: Using custom AlexNetLike, ignoring 'use_pretrained'.\")\n","\n","    elif model_name.lower() == 'vgg16':\n","        model = models.vgg16(weights=weights, aux_logits=False)\n","        num_ftrs = model.classifier[6].in_features\n","        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n","\n","    elif model_name.lower() == 'googlenet':\n","        model = models.googlenet(weights=weights)\n","        model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","    elif model_name.lower() == 'resnet50':\n","        model = models.resnet50(weights=weights)\n","        num_ftrs = model.fc.in_features\n","        model.fc = nn.Sequential(\n","        nn.Dropout(p=0.3),\n","        nn.Linear(num_ftrs, num_classes)\n","        )\n","\n","    else:\n","        raise ValueError(f\"Unknown model name: {model_name}. Choose from 'alexnet', 'vgg16', 'googlenet', 'resnet50'\")\n","\n","    return model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H56_ULwNi61i"},"outputs":[],"source":["# 학습\n","def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, patience):\n","    print(\"=== 학습 시작 ===\")\n","\n","    best_val_loss = float('inf')\n","    best_model_weights = None\n","    epochs_no_improve = 0\n","\n","    for epoch in range(epochs):\n","        start_time = time.time()\n","\n","        # --- 훈련 ---\n","        model.train()\n","        running_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        # tqdm으로 진행 상황 표시\n","        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n","\n","        for images, labels in train_pbar:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # 순전파\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            # 역전파 및 최적화\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * images.size(0)\n","\n","            # 정확도 계산\n","            preds = torch.sigmoid(outputs) > 0.5\n","            total_train += labels.size(0)\n","            correct_train += (preds == labels).sum().item()\n","\n","            train_pbar.set_postfix({'loss': loss.item()})\n","\n","        epoch_train_loss = running_loss / len(train_loader.dataset)\n","        epoch_train_acc = correct_train / total_train\n","\n","        # --- 검증 ---\n","        model.eval()\n","        running_val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","\n","        with torch.no_grad():\n","            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n","            for images, labels in val_pbar:\n","                images, labels = images.to(device), labels.to(device)\n","\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","\n","                running_val_loss += loss.item() * images.size(0)\n","\n","                preds = torch.sigmoid(outputs) > 0.5\n","                total_val += labels.size(0)\n","                correct_val += (preds == labels).sum().item()\n","\n","        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n","        epoch_val_acc = correct_val / total_val\n","\n","        elapsed_time = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1}/{epochs} - {elapsed_time:.0f}s - \"\n","              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} - \"\n","              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n","\n","        # --- Early Stopping 및 Best Model 저장 ---\n","        if epoch_val_loss < best_val_loss:\n","            print(f\"  Validation loss decreased ({best_val_loss:.4f} --> {epoch_val_loss:.4f}). Saving model...\")\n","            best_val_loss = epoch_val_loss\n","            best_model_weights = copy.deepcopy(model.state_dict())\n","            torch.save(best_model_weights, MODEL_SAVE_PATH)\n","            epochs_no_improve = 0\n","        else:\n","            epochs_no_improve += 1\n","            print(f\"  Validation loss did not improve. Patience: {epochs_no_improve}/{patience}\")\n","\n","        if epochs_no_improve >= patience:\n","            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","            break\n","\n","        scheduler.step(epoch_val_loss)\n","\n","    print(\"=== 학습 완료 ===\")\n","    model.load_state_dict(best_model_weights)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"df3H5EVywjeb"},"outputs":[],"source":["# 평가\n","def evaluate_model(model, test_loader, criterion, device):\n","    model.eval()\n","    running_test_loss = 0.0\n","    correct_test = 0\n","    total_test = 0\n","\n","    print(\"\\n=== 테스트셋 평가 시작 ===\")\n","    with torch.no_grad():\n","        test_pbar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n","        for images, labels in test_pbar:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_test_loss += loss.item() * images.size(0)\n","\n","            preds = torch.sigmoid(outputs) > 0.5\n","            total_test += labels.size(0)\n","            correct_test += (preds == labels).sum().item()\n","\n","    test_loss = running_test_loss / len(test_loader.dataset)\n","    test_acc = correct_test / total_test\n","\n","    print(f\"===== 최종 테스트 결과 =====\")\n","    print(f\"  Test Loss: {test_loss:.4f}\")\n","    print(f\"  Test Accuracy: {test_acc * 100:.2f}%\")"]},{"cell_type":"code","source":["# 데이터 path 만들기\n","def load_and_sample(real_dir, fake_dir, n_samples=None):\n","    real_paths = []\n","    fake_paths = []\n","\n","    real_paths.extend(glob.glob(os.path.join(real_dir, \"*.*\")))\n","    fake_paths.extend(glob.glob(os.path.join(fake_dir, \"*.*\")))\n","\n","    paths = real_paths + fake_paths\n","    labels = [0] * len(real_paths) + [1] * len(fake_paths)\n","    total = len(paths)\n","\n","    print(f\"경로: {os.path.dirname(real_dir)}\")\n","    print(f\"개수: {total}장 (Real: {len(real_paths)}, Fake: {len(fake_paths)})\")\n","\n","    if n_samples is None or n_samples >= total:\n","        print(f\"  - 전체 데이터 사용 ({total}장)\")\n","        # 셔플만 수행\n","        combined = list(zip(paths, labels))\n","        np.random.shuffle(combined)\n","        paths[:], labels[:] = zip(*combined)\n","        return paths, labels\n","\n","    else:\n","        print(f\"  - 샘플링: {n_samples}장 선택 (Stratified)\")\n","\n","        sampled_paths, _, sampled_labels, _ = train_test_split(\n","            paths, labels,\n","            train_size=n_samples,\n","            stratify=labels,\n","            random_state=42\n","        )\n","        return sampled_paths, sampled_labels"],"metadata":{"id":"iTWoO8jEwYKR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메인 실행\n","start_time = time.time()\n","\n","# GPU 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# 데이터 경로 및 라벨 수집\n","base_path = \"/content/dataset/Dataset/\"\n","train_path = base_path + 'Train'\n","validdation_path = base_path + 'Validation'\n","test_path = base_path + 'Test'\n","MODEL_SAVE_PATH = \"/content/drive/MyDrive/deepfake_model.pth\"\n","\n","NUM_TRAIN_SAMPLES = 14000\n","NUM_VAL_SAMPLES = 4000\n","NUM_TEST_SAMPLES = 2000    # None: 전체 사용\n","\n","print(\"\\n=== [Train Set] 준비 ===\")\n","train_paths, train_labels = load_and_sample(\n","    os.path.join(train_path, 'Real'),\n","    os.path.join(train_path, 'Fake'),\n","    NUM_TRAIN_SAMPLES\n",")\n","\n","print(\"\\n=== [Validation Set] 준비 ===\")\n","val_paths, val_labels = load_and_sample(\n","    os.path.join(validdation_path, 'Real'),\n","    os.path.join(validdation_path, 'Fake'),\n","    NUM_VAL_SAMPLES\n",")\n","\n","print(\"\\n=== [Test Set] 준비 ===\")\n","test_paths, test_labels = load_and_sample(\n","    os.path.join(test_path, 'Real'),\n","    os.path.join(test_path, 'Fake'),\n","    NUM_TEST_SAMPLES\n",")\n","\n","#target_labels = list(set((train_labels + val_labels + test_labels)))\n","\n","# 4. 결과 확인\n","print(f\"\\n최종 데이터셋 구성:\")\n","print(f\"  Train: {len(train_paths)}장\")\n","print(f\"  Val  : {len(val_paths)}장\")\n","print(f\"  Test : {len(test_paths)}장\")"],"metadata":{"id":"9kzTIAFLwhv7","executionInfo":{"status":"ok","timestamp":1763910405116,"user_tz":-540,"elapsed":537,"user":{"displayName":"김윤숙","userId":"06661495915909363949"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e81367f4-df6a-464a-87b3-46b96e922bc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","=== [Train Set] 준비 ===\n","경로: /content/dataset/Dataset/Train\n","개수: 140002장 (Real: 70001, Fake: 70001)\n","  - 샘플링: 14000장 선택 (Stratified)\n","\n","=== [Validation Set] 준비 ===\n","경로: /content/dataset/Dataset/Validation\n","개수: 39428장 (Real: 19787, Fake: 19641)\n","  - 샘플링: 4000장 선택 (Stratified)\n","\n","=== [Test Set] 준비 ===\n","경로: /content/dataset/Dataset/Test\n","개수: 10905장 (Real: 5413, Fake: 5492)\n","  - 샘플링: 2000장 선택 (Stratified)\n","\n","최종 데이터셋 구성:\n","  Train: 14000장\n","  Val  : 4000장\n","  Test : 2000장\n"]}]},{"cell_type":"code","source":["#데이터 로더 정의\n","train_transform = transforms.Compose([\n","    ResizeWithPad(IMG_SIZE),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n","    transforms.RandomRotation(degrees=5),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) ])\n","val_test_transform = transforms.Compose([\n","    ResizeWithPad(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","train_dataset = DeepfakeDataset(train_paths, train_labels, transform=train_transform)\n","val_dataset = DeepfakeDataset(val_paths, val_labels, transform=val_test_transform)\n","test_dataset = DeepfakeDataset(test_paths, test_labels, transform=val_test_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","\n","print(\"데이터 로더 생성 완료.\")"],"metadata":{"id":"RjrkSyrdw4VK","executionInfo":{"status":"ok","timestamp":1763910407385,"user_tz":-540,"elapsed":35,"user":{"displayName":"김윤숙","userId":"06661495915909363949"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a46fcac2-e79a-4a38-ce24-86817fe37385"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 로더 생성 완료.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRUieuirwjed","executionInfo":{"status":"ok","timestamp":1763912603501,"user_tz":-540,"elapsed":55,"user":{"displayName":"김윤숙","userId":"06661495915909363949"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"073a5c6b-02e4-47b3-fca2-392df0505c2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 로더 생성 완료.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}],"source":["# 전처리 및 데이터 로더 정의\n","train_transform = transforms.Compose([\n","    ResizeWithPad(IMG_SIZE),\n","    transforms.RandomHorizontalFlip(), # 데이터 증강\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # -1 ~ 1 정규화\n","])\n","\n","val_test_transform = transforms.Compose([\n","    ResizeWithPad(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","train_dataset = DeepfakeDataset(train_paths, train_labels, transform=train_transform)\n","val_dataset = DeepfakeDataset(val_paths, val_labels, transform=val_test_transform)\n","test_dataset = DeepfakeDataset(test_paths, test_labels, transform=val_test_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n","\n","print(\"데이터 로더 생성 완료.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4_5lk7hwjed","executionInfo":{"status":"ok","timestamp":1763914716259,"user_tz":-540,"elapsed":2109699,"user":{"displayName":"김윤숙","userId":"06661495915909363949"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bdb112e7-062e-4b4e-c540-e1a1da5689ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 로더(디스크 기반)를 사용하여 학습을 시작합니다.\n","Loading googlenet architecture...\n","  Using ImageNet Pre-trained Weights.\n","=== 학습 시작 ===\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30 - 70s - Train Loss: 0.6754, Train Acc: 0.5836 - Val Loss: 0.6425, Val Acc: 0.7100\n","  Validation loss decreased (inf --> 0.6425). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2/30 - 70s - Train Loss: 0.6250, Train Acc: 0.7063 - Val Loss: 0.5988, Val Acc: 0.7445\n","  Validation loss decreased (0.6425 --> 0.5988). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3/30 - 69s - Train Loss: 0.5900, Train Acc: 0.7387 - Val Loss: 0.5709, Val Acc: 0.7542\n","  Validation loss decreased (0.5988 --> 0.5709). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4/30 - 69s - Train Loss: 0.5646, Train Acc: 0.7544 - Val Loss: 0.5492, Val Acc: 0.7628\n","  Validation loss decreased (0.5709 --> 0.5492). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5/30 - 69s - Train Loss: 0.5461, Train Acc: 0.7599 - Val Loss: 0.5345, Val Acc: 0.7610\n","  Validation loss decreased (0.5492 --> 0.5345). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6/30 - 69s - Train Loss: 0.5313, Train Acc: 0.7647 - Val Loss: 0.5246, Val Acc: 0.7615\n","  Validation loss decreased (0.5345 --> 0.5246). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7/30 - 69s - Train Loss: 0.5188, Train Acc: 0.7689 - Val Loss: 0.5142, Val Acc: 0.7672\n","  Validation loss decreased (0.5246 --> 0.5142). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8/30 - 68s - Train Loss: 0.5086, Train Acc: 0.7714 - Val Loss: 0.5060, Val Acc: 0.7660\n","  Validation loss decreased (0.5142 --> 0.5060). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9/30 - 69s - Train Loss: 0.5001, Train Acc: 0.7779 - Val Loss: 0.5017, Val Acc: 0.7692\n","  Validation loss decreased (0.5060 --> 0.5017). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10/30 - 69s - Train Loss: 0.4936, Train Acc: 0.7780 - Val Loss: 0.4971, Val Acc: 0.7680\n","  Validation loss decreased (0.5017 --> 0.4971). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 11/30 - 70s - Train Loss: 0.4890, Train Acc: 0.7794 - Val Loss: 0.4934, Val Acc: 0.7692\n","  Validation loss decreased (0.4971 --> 0.4934). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 12/30 - 70s - Train Loss: 0.4845, Train Acc: 0.7781 - Val Loss: 0.4881, Val Acc: 0.7680\n","  Validation loss decreased (0.4934 --> 0.4881). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 13/30 - 68s - Train Loss: 0.4772, Train Acc: 0.7864 - Val Loss: 0.4855, Val Acc: 0.7665\n","  Validation loss decreased (0.4881 --> 0.4855). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 14/30 - 69s - Train Loss: 0.4747, Train Acc: 0.7834 - Val Loss: 0.4841, Val Acc: 0.7715\n","  Validation loss decreased (0.4855 --> 0.4841). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 15/30 - 70s - Train Loss: 0.4746, Train Acc: 0.7812 - Val Loss: 0.4798, Val Acc: 0.7708\n","  Validation loss decreased (0.4841 --> 0.4798). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 16/30 - 72s - Train Loss: 0.4666, Train Acc: 0.7876 - Val Loss: 0.4770, Val Acc: 0.7722\n","  Validation loss decreased (0.4798 --> 0.4770). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 17/30 - 71s - Train Loss: 0.4673, Train Acc: 0.7876 - Val Loss: 0.4784, Val Acc: 0.7735\n","  Validation loss did not improve. Patience: 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 18/30 - 71s - Train Loss: 0.4588, Train Acc: 0.7926 - Val Loss: 0.4760, Val Acc: 0.7750\n","  Validation loss decreased (0.4770 --> 0.4760). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 19/30 - 71s - Train Loss: 0.4598, Train Acc: 0.7899 - Val Loss: 0.4741, Val Acc: 0.7745\n","  Validation loss decreased (0.4760 --> 0.4741). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 20/30 - 71s - Train Loss: 0.4573, Train Acc: 0.7889 - Val Loss: 0.4717, Val Acc: 0.7762\n","  Validation loss decreased (0.4741 --> 0.4717). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 21/30 - 71s - Train Loss: 0.4575, Train Acc: 0.7888 - Val Loss: 0.4723, Val Acc: 0.7760\n","  Validation loss did not improve. Patience: 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 22/30 - 70s - Train Loss: 0.4531, Train Acc: 0.7933 - Val Loss: 0.4714, Val Acc: 0.7735\n","  Validation loss decreased (0.4717 --> 0.4714). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 23/30 - 70s - Train Loss: 0.4510, Train Acc: 0.7941 - Val Loss: 0.4735, Val Acc: 0.7738\n","  Validation loss did not improve. Patience: 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 24/30 - 71s - Train Loss: 0.4482, Train Acc: 0.7945 - Val Loss: 0.4680, Val Acc: 0.7780\n","  Validation loss decreased (0.4714 --> 0.4680). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 25/30 - 71s - Train Loss: 0.4479, Train Acc: 0.7901 - Val Loss: 0.4687, Val Acc: 0.7762\n","  Validation loss did not improve. Patience: 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 26/30 - 71s - Train Loss: 0.4465, Train Acc: 0.7956 - Val Loss: 0.4664, Val Acc: 0.7750\n","  Validation loss decreased (0.4680 --> 0.4664). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 27/30 - 71s - Train Loss: 0.4468, Train Acc: 0.7951 - Val Loss: 0.4673, Val Acc: 0.7758\n","  Validation loss did not improve. Patience: 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 28/30 - 70s - Train Loss: 0.4444, Train Acc: 0.7944 - Val Loss: 0.4661, Val Acc: 0.7772\n","  Validation loss decreased (0.4664 --> 0.4661). Saving model...\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 29/30 - 71s - Train Loss: 0.4440, Train Acc: 0.7966 - Val Loss: 0.4664, Val Acc: 0.7755\n","  Validation loss did not improve. Patience: 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 30/30 - 71s - Train Loss: 0.4443, Train Acc: 0.7921 - Val Loss: 0.4642, Val Acc: 0.7790\n","  Validation loss decreased (0.4661 --> 0.4642). Saving model...\n","=== 학습 완료 ===\n","\n","=== 테스트셋 평가 시작 ===\n"]},{"output_type":"stream","name":"stderr","text":["                                                       "]},{"output_type":"stream","name":"stdout","text":["===== 최종 테스트 결과 =====\n","  Test Loss: 0.5413\n","  Test Accuracy: 72.35%\n","총 실행 시간: 71.86 분\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["print(\"데이터 로더(디스크 기반)를 사용하여 학습을 시작합니다.\")\n","\n","#모델, 손실함수, 옵티마이저 정의\n","MODEL_NAME = 'googlenet'\n","# use_pretrained 사용\n","model = get_model(MODEL_NAME, device, use_pretrained=True)\n","# 모든 파라미터를 동결\n","for name, param in model.named_parameters():\n","    param.requires_grad = False\n","\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer,\n","    mode='min',\n","    factor=0.1,\n","    patience=3,\n","    #verbose=True\n",")\n","\n","#학습 및 평가\n","model = train_model(model, train_loader, val_loader, criterion, optimizer, device, EPOCHS, PATIENCE)\n","\n","evaluate_model(model, test_loader, criterion, device)\n","\n","print(f\"총 실행 시간: {(time.time() - start_time) / 60:.2f} 분\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"history_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.8"}},"nbformat":4,"nbformat_minor":0}
